{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00f504d0",
   "metadata": {},
   "source": [
    "\n",
    "#Sentiment Classification for E-commerce Customer Feedback\n",
    "\n",
    "## Business Context\n",
    "In todayâ€™s fast-paced e-commerce landscape, **customer reviews significantly influence product perception and buying decisions**. Businesses must actively monitor customer sentiment to extract insights and maintain a competitive edge. Ignoring negative feedback can lead to serious consequences such as:\n",
    "\n",
    "- **Customer Churn**: Unresolved complaints drive loyal customers away, reducing retention and future revenue.  \n",
    "- **Reputation Damage**: Persistent negative sentiment erodes brand trust and deters new buyers.  \n",
    "- **Financial Loss**: Declining sales and shifting preferences toward competitors directly impact profitability.  \n",
    "\n",
    "With a **200% increase in customer base over three years** and a recent **25% spike in feedback volume**, manual review of feedback is unsustainable.  \n",
    "\n",
    "ðŸ‘‰ The company aims to **implement an AI-driven solution** to automatically classify customer sentiment (**positive, negative, neutral**) from product reviews, surveys, and social media.  \n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "As a Data Scientist, your task is to:\n",
    "1. **Analyze** the provided customer reviews dataset.  \n",
    "2. **Preprocess** and clean the data.  \n",
    "3. **Build predictive models** for sentiment classification:  \n",
    "   - Traditional ML baselines (TF-IDF + Logistic Regression / SVM).  \n",
    "   - Transformer-based fine-tuned model (DistilBERT).  \n",
    "4. **Evaluate** models on accuracy and F1 scores.  \n",
    "5. Provide insights and recommendations for deployment in real-world monitoring systems.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84788fc6",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd08b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install dependencies (uncomment if running in a clean environment)\n",
    "# %pip install pandas numpy scikit-learn matplotlib seaborn\n",
    "# %pip install transformers datasets evaluate accelerate torch\n",
    "# %pip install fastapi uvicorn emoji textblob wordcloud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c689d900",
   "metadata": {},
   "source": [
    "## 2) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94c9de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, re, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding,\n",
    "    TrainingArguments, Trainer\n",
    ")\n",
    "import evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca782302",
   "metadata": {},
   "source": [
    "## 3) Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c183b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set your dataset path here (CSV with columns: Review, Sentiment)\n",
    "DATA_PATH = \"customer_feedback.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Normalize column names\n",
    "df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "\n",
    "assert \"sentiment\" in df.columns, \"Dataset must include 'sentiment' column\"\n",
    "assert any(\"review\" in c for c in df.columns), \"Dataset must include a review text column\"\n",
    "\n",
    "text_col = [c for c in df.columns if \"review\" in c][0]\n",
    "df = df[[text_col, \"sentiment\"]].rename(columns={text_col: \"text\"})\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b91e94",
   "metadata": {},
   "source": [
    "## 4) Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a1355",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Dataset size:\", len(df))\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df[\"sentiment\"].value_counts())\n",
    "\n",
    "df[\"text_length\"] = df[\"text\"].str.split().str.len()\n",
    "df[\"text_length\"].hist(bins=40)\n",
    "plt.title(\"Review Length Distribution\")\n",
    "plt.xlabel(\"Words per review\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f6179",
   "metadata": {},
   "source": [
    "## 5) Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import emoji\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"http\\S+|www\\.\\S+\", \" \", s)\n",
    "    s = re.sub(r\"@\\w+|#\\w+\", \" \", s)\n",
    "    s = emoji.replace_emoji(s, replace=\" \")\n",
    "    s = re.sub(r\"[^a-z0-9\\s\\.\\,\\!\\?]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "df[\"text_clean\"] = df[\"text\"].map(clean_text)\n",
    "\n",
    "label2id = {\"negative\":0, \"neutral\":1, \"positive\":2}\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "df[\"y\"] = df[\"sentiment\"].str.lower().map(label2id)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbc588e",
   "metadata": {},
   "source": [
    "## 6) Train / Validation / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491635d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"y\"])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"y\"])\n",
    "print(\"Train:\", train_df.shape, \"Val:\", val_df.shape, \"Test:\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9506305d",
   "metadata": {},
   "source": [
    "## 7) Baseline Models (TF-IDF + LR / SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e30b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, y_train = train_df[\"text_clean\"], train_df[\"y\"]\n",
    "X_val, y_val = val_df[\"text_clean\"], val_df[\"y\"]\n",
    "X_test, y_test = test_df[\"text_clean\"], test_df[\"y\"]\n",
    "\n",
    "# Logistic Regression\n",
    "pipe_lr = Pipeline([(\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=2)), \n",
    "                    (\"clf\", LogisticRegression(max_iter=200))])\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "val_pred_lr = pipe_lr.predict(X_val)\n",
    "print(\"Validation Report (LR):\\n\", classification_report(y_val, val_pred_lr))\n",
    "\n",
    "# SVM\n",
    "pipe_svm = Pipeline([(\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=2)), \n",
    "                     (\"clf\", LinearSVC())])\n",
    "pipe_svm.fit(X_train, y_train)\n",
    "val_pred_svm = pipe_svm.predict(X_val)\n",
    "print(\"Validation Report (SVM):\\n\", classification_report(y_val, val_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f394130",
   "metadata": {},
   "source": [
    "## 8) Transformer Model (DistilBERT Fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df25c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df[[\"text\", \"y\"]].rename(columns={\"y\":\"labels\"}))\n",
    "val_ds = Dataset.from_pandas(val_df[[\"text\", \"y\"]].rename(columns={\"y\":\"labels\"}))\n",
    "test_ds = Dataset.from_pandas(test_df[[\"text\", \"y\"]].rename(columns={\"y\":\"labels\"}))\n",
    "\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True)\n",
    "val_ds = val_ds.map(tokenize_fn, batched=True)\n",
    "test_ds = test_ds.map(tokenize_fn, batched=True)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=3, id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "metric_f1 = evaluate.load(\"f1\")\n",
    "metric_acc = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": metric_acc.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1_macro\": metric_f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"outputs\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883e0666",
   "metadata": {},
   "source": [
    "## 9) Evaluation & Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate transformer on test set\n",
    "test_metrics = trainer.evaluate(test_ds)\n",
    "print(\"Transformer Test Metrics:\", test_metrics)\n",
    "\n",
    "# Misclassified examples\n",
    "preds = trainer.predict(test_ds).predictions.argmax(axis=-1)\n",
    "mis_idx = np.where(preds != test_df[\"y\"].values)[0].tolist()\n",
    "for i in mis_idx[:5]:\n",
    "    print(\"---\")\n",
    "    print(\"Text:\", test_df.iloc[i][\"text\"][:300])\n",
    "    print(\"True:\", id2label[test_df.iloc[i][\"y\"]], \"Pred:\", id2label[preds[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a684b610",
   "metadata": {},
   "source": [
    "## 10) Inference Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1755d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_sentiment(texts, model, tokenizer):\n",
    "    enc = tokenizer(texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(**enc).logits\n",
    "    preds = logits.argmax(dim=-1).tolist()\n",
    "    return [id2label[p] for p in preds]\n",
    "\n",
    "# Example\n",
    "# predict_sentiment([\"Great product, loved the battery life!\", \"Worst experience ever!\"], model, tokenizer)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
